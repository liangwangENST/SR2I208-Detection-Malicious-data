{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net\n",
    "In this file, we test the neural net for all kind of attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3143389564535112"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_attack1 = pd.read_csv(\"dataset/attack1with7FeatureVector.csv\")\n",
    "data_attack1 = data_attack1.dropna(axis=0, how=\"any\")#remove invalid data\n",
    "sum(np.array(data_attack1['Label']))/data_attack1['Label'].shape[0]/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_func = ['sigmoid','softmax', 'elu', 'selu', 'softplus', 'softsign', \n",
    "                   'relu', 'tanh', 'hard_sigmoid', 'linear']\n",
    "loss_func = ['binary_crossentropy', 'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error',\n",
    "            'mean_squared_logarithmic_error', 'squared_hinge', 'hinge', 'logcosh', 'kullback_leibler_divergence', \n",
    "            'poisson', 'cosine_proximity']\n",
    "optimizer_scheme = ['Adagrad','SGD', 'RMSprop', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********For the activation function sigmoid ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 3s 115us/step - loss: 0.2750 - binary_accuracy: 0.9193\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 22us/step - loss: 0.1346 - binary_accuracy: 0.9622\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 20us/step - loss: 0.1006 - binary_accuracy: 0.9745\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0860 - binary_accuracy: 0.9827\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0775 - binary_accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0721 - binary_accuracy: 0.9841\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0681 - binary_accuracy: 0.9848\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0658 - binary_accuracy: 0.9850\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0634 - binary_accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0619 - binary_accuracy: 0.9861\n",
      "6118/6118 [==============================] - 1s 241us/step\n",
      "For attack1: The loss is 0.056002680070992975 , the accuracy is 0.9877410913729597\n",
      "********For the activation function softmax ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 186us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 10.9167 - binary_accuracy: 0.3152\n",
      "6118/6118 [==============================] - 2s 261us/step\n",
      "For attack1: The loss is 10.988727391253269 , the accuracy is 0.3107224584561074\n",
      "********For the activation function elu ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 4s 159us/step - loss: 1.2320 - binary_accuracy: 0.4437\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.4453 - binary_accuracy: 0.3821\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.4285 - binary_accuracy: 0.3846\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.4065 - binary_accuracy: 0.3855\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.4078 - binary_accuracy: 0.3894\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.3801 - binary_accuracy: 0.3987\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 29us/step - loss: 0.4098 - binary_accuracy: 0.4009\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.3796 - binary_accuracy: 0.4050\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.6679 - binary_accuracy: 0.4933\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.7571 - binary_accuracy: 0.4914\n",
      "6118/6118 [==============================] - 2s 257us/step\n",
      "For attack1: The loss is 0.7962449373237134 , the accuracy is 0.4727034978946076\n",
      "********For the activation function selu ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 201us/step - loss: 3.5334 - binary_accuracy: 0.0898\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 1.0141 - binary_accuracy: 0.1665\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 1.0100 - binary_accuracy: 0.1626\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 2.6959 - binary_accuracy: 0.1247\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 1.0065 - binary_accuracy: 0.0985\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 35us/step - loss: 0.9432 - binary_accuracy: 0.1268\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 35us/step - loss: 4.0609 - binary_accuracy: 0.1191\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 4.4552 - binary_accuracy: 0.1223\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 4.4546 - binary_accuracy: 0.1180\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 4.4533 - binary_accuracy: 0.1205\n",
      "6118/6118 [==============================] - 2s 261us/step\n",
      "For attack1: The loss is 4.448660283121419 , the accuracy is 0.11212814656512805\n",
      "********For the activation function softplus ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 201us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 38us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 38us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 39us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 38us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 39us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 40us/step - loss: 10.9597 - binary_accuracy: 0.0000e+00\n",
      "6118/6118 [==============================] - 2s 277us/step\n",
      "For attack1: The loss is 10.816743533336169 , the accuracy is 0.0\n",
      "********For the activation function softsign ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 207us/step - loss: 0.3296 - binary_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 38us/step - loss: 0.2404 - binary_accuracy: 0.9598\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 0.2240 - binary_accuracy: 0.6665\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 30us/step - loss: 0.2108 - binary_accuracy: 0.5054\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 30us/step - loss: 0.2066 - binary_accuracy: 0.4445\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 30us/step - loss: 0.1981 - binary_accuracy: 0.4301\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 0.2037 - binary_accuracy: 0.4068\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 0.1972 - binary_accuracy: 0.3738\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.1900 - binary_accuracy: 0.3819\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 30us/step - loss: 0.1917 - binary_accuracy: 0.3862\n",
      "6118/6118 [==============================] - 2s 274us/step\n",
      "For attack1: The loss is 0.15436317536635272 , the accuracy is 0.3906505394796407\n",
      "********For the activation function relu ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 205us/step - loss: 3.2690 - binary_accuracy: 0.6973\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24470/24470 [==============================] - 1s 33us/step - loss: 1.8795 - binary_accuracy: 0.6281\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.9251 - binary_accuracy: 0.6569\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.2848 - binary_accuracy: 0.7091\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.4810 - binary_accuracy: 0.7051\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 3.7229 - binary_accuracy: 0.7139\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 3.4483 - binary_accuracy: 0.7115\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 1.0315 - binary_accuracy: 0.6504\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 0.5735 - binary_accuracy: 0.6707\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.3128 - binary_accuracy: 0.6949\n",
      "6118/6118 [==============================] - 2s 277us/step\n",
      "For attack1: The loss is 0.11324128096459854 , the accuracy is 0.7204968942150878\n",
      "********For the activation function tanh ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 202us/step - loss: 4.6348 - binary_accuracy: 0.1870\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 30us/step - loss: 4.5907 - binary_accuracy: 0.1526\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 4.5653 - binary_accuracy: 0.1848\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 4.5613 - binary_accuracy: 0.1821\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 4.5593 - binary_accuracy: 0.1859\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 30us/step - loss: 4.5595 - binary_accuracy: 0.1853\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 4.5578 - binary_accuracy: 0.1864\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 4.5559 - binary_accuracy: 0.1919\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 4.5493 - binary_accuracy: 0.2035\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 4.5479 - binary_accuracy: 0.2036\n",
      "6118/6118 [==============================] - 2s 288us/step\n",
      "For attack1: The loss is 4.413847927487571 , the accuracy is 0.2054593006587956\n",
      "********For the activation function hard_sigmoid ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 209us/step - loss: 0.2463 - binary_accuracy: 0.9128\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.1249 - binary_accuracy: 0.9498\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 0.1127 - binary_accuracy: 0.9623\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 0.1061 - binary_accuracy: 0.9657\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.1001 - binary_accuracy: 0.9678\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.0969 - binary_accuracy: 0.9692\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 35us/step - loss: 0.0930 - binary_accuracy: 0.9813\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.0904 - binary_accuracy: 0.9825\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.0885 - binary_accuracy: 0.9827\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 35us/step - loss: 0.0871 - binary_accuracy: 0.9829\n",
      "6118/6118 [==============================] - 2s 288us/step\n",
      "For attack1: The loss is 0.09065832566419978 , the accuracy is 0.9810395554492348\n",
      "********For the activation function linear ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 208us/step - loss: 4.5293 - binary_accuracy: 0.2943\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 4.6331 - binary_accuracy: 0.1524\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 4.5735 - binary_accuracy: 0.2015\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 4.5869 - binary_accuracy: 0.1973\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 4.5855 - binary_accuracy: 0.2049\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 4.5825 - binary_accuracy: 0.2118\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 4.5810 - binary_accuracy: 0.2259\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 35us/step - loss: 4.0449 - binary_accuracy: 0.3604\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 4.4036 - binary_accuracy: 0.2605\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 2.8525 - binary_accuracy: 0.1859\n",
      "6118/6118 [==============================] - 2s 295us/step\n",
      "For attack1: The loss is 4.058997022205414 , the accuracy is 0.05867930698619827\n"
     ]
    }
   ],
   "source": [
    "data_attack1.shape\n",
    "\n",
    "X = data_attack1.iloc[:,12:] #In our case, we use the feature of 1-6, the feature of distance rejected\n",
    "n = X.shape[1]\n",
    "y = data_attack1.iloc[:,11]\n",
    "X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "y =np.reshape(y.values, (y.shape[0],  1))\n",
    "\n",
    "activation_func_use = activation_func[0]\n",
    "loss_func_use = loss_func[0]\n",
    "optimizer_scheme_use = optimizer_scheme[0]\n",
    "\n",
    "for i in range(len(activation_func)):\n",
    "    activation_func_use = activation_func[i]\n",
    "    print('********For the activation function', activation_func[i], '********')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "    model.add(Dense(16, activation=activation_func_use))\n",
    "    model.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "    model.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "    loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "    print('For attack1: The loss is', loss_and_metrics[0], ', the accuracy is', loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that only the sigmoid function and hard_sigmoid function are valid for this kind of data set.\n",
    "We thus choose the Sigmoid funcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********For the loss function binary_crossentropy ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 77us/step - loss: 0.2529 - binary_accuracy: 0.9245\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.1229 - binary_accuracy: 0.9658\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0939 - binary_accuracy: 0.9756\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0811 - binary_accuracy: 0.9831\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0730 - binary_accuracy: 0.9843\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0683 - binary_accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0646 - binary_accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0624 - binary_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0606 - binary_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0594 - binary_accuracy: 0.9869\n",
      "6118/6118 [==============================] - 1s 102us/step\n",
      "For attack1: The loss is 0.06463440688130279 , the accuracy is 0.9861065702876377\n",
      "********For the loss function mean_squared_error ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 74us/step - loss: 0.0829 - binary_accuracy: 0.9189\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0377 - binary_accuracy: 0.9607\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0271 - binary_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0225 - binary_accuracy: 0.9826\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0196 - binary_accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0178 - binary_accuracy: 0.9848\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0163 - binary_accuracy: 0.9855\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0154 - binary_accuracy: 0.9862\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0148 - binary_accuracy: 0.9863\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 13us/step - loss: 0.0142 - binary_accuracy: 0.9866\n",
      "6118/6118 [==============================] - 1s 101us/step\n",
      "For attack1: The loss is 0.014294096382579 , the accuracy is 0.9867603792088918\n",
      "********For the loss function mean_absolute_error ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 75us/step - loss: 0.2238 - binary_accuracy: 0.8394\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 13us/step - loss: 0.0977 - binary_accuracy: 0.9367\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0751 - binary_accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0559 - binary_accuracy: 0.9678\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0462 - binary_accuracy: 0.9714\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 13us/step - loss: 0.0409 - binary_accuracy: 0.9724\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 13us/step - loss: 0.0347 - binary_accuracy: 0.9786\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0294 - binary_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0257 - binary_accuracy: 0.9873\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0232 - binary_accuracy: 0.9877\n",
      "6118/6118 [==============================] - 1s 104us/step\n",
      "For attack1: The loss is 0.020787775666453248 , the accuracy is 0.9888852566198104\n",
      "********For the loss function mean_absolute_percentage_error ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 77us/step - loss: 48768117.8995 - binary_accuracy: 0.6850\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 14545165.7585 - binary_accuracy: 0.6863\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 8591058.3854 - binary_accuracy: 0.6863\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 6200795.7773 - binary_accuracy: 0.6863\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 4884323.7998 - binary_accuracy: 0.6863\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 4040233.8426 - binary_accuracy: 0.6863\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 3449924.1015 - binary_accuracy: 0.6863\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 3012639.1090 - binary_accuracy: 0.6863\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 2675333.2721 - binary_accuracy: 0.6863\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 2406828.5006 - binary_accuracy: 0.6863\n",
      "6118/6118 [==============================] - 1s 105us/step\n",
      "For attack1: The loss is 2279680.115642367 , the accuracy is 0.6830663618678242\n",
      "********For the loss function mean_squared_logarithmic_error ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 80us/step - loss: 0.0357 - binary_accuracy: 0.9172\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0165 - binary_accuracy: 0.9611\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0124 - binary_accuracy: 0.9694\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0103 - binary_accuracy: 0.9747\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0092 - binary_accuracy: 0.9837\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0083 - binary_accuracy: 0.9848\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0077 - binary_accuracy: 0.9851\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0072 - binary_accuracy: 0.9859: 0s - loss: 0.0072 - binary_accuracy: 0.98\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0068 - binary_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0066 - binary_accuracy: 0.9868\n",
      "6118/6118 [==============================] - 1s 113us/step\n",
      "For attack1: The loss is 0.0072430011063714305 , the accuracy is 0.984472049708926\n",
      "********For the loss function squared_hinge ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 82us/step - loss: 0.6884 - binary_accuracy: 0.3137\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.6866 - binary_accuracy: 0.3137\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.6864 - binary_accuracy: 0.3137\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6864 - binary_accuracy: 0.3137\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6864 - binary_accuracy: 0.3137\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.6864 - binary_accuracy: 0.3137\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6863 - binary_accuracy: 0.3137\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6863 - binary_accuracy: 0.3137\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6863 - binary_accuracy: 0.3137\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6863 - binary_accuracy: 0.3137\n",
      "6118/6118 [==============================] - 1s 107us/step\n",
      "For attack1: The loss is 0.6832758119270746 , the accuracy is 0.31677018644257127\n",
      "********For the loss function hinge ********\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24470/24470 [==============================] - 2s 81us/step - loss: 0.6999 - binary_accuracy: 0.3128\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6913 - binary_accuracy: 0.3128\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6900 - binary_accuracy: 0.3128\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6894 - binary_accuracy: 0.3128\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6890 - binary_accuracy: 0.3128\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6887 - binary_accuracy: 0.3128\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6885 - binary_accuracy: 0.3128\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6883 - binary_accuracy: 0.3128\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.6882 - binary_accuracy: 0.3128\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.6881 - binary_accuracy: 0.3128\n",
      "6118/6118 [==============================] - 1s 117us/step\n",
      "For attack1: The loss is 0.6801775260936517 , the accuracy is 0.3206930370960566\n",
      "********For the loss function logcosh ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 83us/step - loss: 0.0340 - binary_accuracy: 0.9250\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0166 - binary_accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0119 - binary_accuracy: 0.9718\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0098 - binary_accuracy: 0.9836\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0085 - binary_accuracy: 0.9848\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0077 - binary_accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0072 - binary_accuracy: 0.9858\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0067 - binary_accuracy: 0.9863\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0063 - binary_accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0062 - binary_accuracy: 0.9868\n",
      "6118/6118 [==============================] - 1s 113us/step\n",
      "For attack1: The loss is 0.006217868732288175 , the accuracy is 0.9870872834259562\n",
      "********For the loss function kullback_leibler_divergence ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 83us/step - loss: 0.0143 - binary_accuracy: 0.3119\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0042 - binary_accuracy: 0.3107\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.0029 - binary_accuracy: 0.3107\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0023 - binary_accuracy: 0.3107\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0019 - binary_accuracy: 0.3107\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0016 - binary_accuracy: 0.3107\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0014 - binary_accuracy: 0.3107\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0012 - binary_accuracy: 0.3107\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0011 - binary_accuracy: 0.3107\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.0010 - binary_accuracy: 0.3107\n",
      "6118/6118 [==============================] - 1s 112us/step\n",
      "For attack1: The loss is 0.001012975554082125 , the accuracy is 0.3288656425129241\n",
      "********For the loss function poisson ********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 85us/step - loss: 0.4580 - binary_accuracy: 0.9181\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3859 - binary_accuracy: 0.9592\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.3688 - binary_accuracy: 0.9686\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3627 - binary_accuracy: 0.9731\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3592 - binary_accuracy: 0.9824\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 14us/step - loss: 0.3568 - binary_accuracy: 0.9839\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3553 - binary_accuracy: 0.9843\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3555 - binary_accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.3535 - binary_accuracy: 0.9848\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.3529 - binary_accuracy: 0.9851\n",
      "6118/6118 [==============================] - 1s 123us/step\n",
      "For attack1: The loss is 0.36656623066504357 , the accuracy is 0.9805491986170279\n",
      "********For the loss function cosine_proximity ********\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3003: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 86us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: -0.3153 - binary_accuracy: 0.3153\n",
      "6118/6118 [==============================] - 1s 119us/step\n",
      "For attack1: The loss is -0.3105589645522293 , the accuracy is 0.3105590063865452\n"
     ]
    }
   ],
   "source": [
    "activation_func_use = activation_func[0]\n",
    "loss_func_use = loss_func[0]\n",
    "optimizer_scheme_use = optimizer_scheme[0]\n",
    "\n",
    "for i in range(len(loss_func)):\n",
    "    loss_func_use = loss_func[i]\n",
    "    print('********For the loss function', loss_func[i], '********')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "    model.add(Dense(16, activation=activation_func_use))\n",
    "    model.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "    model.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "    loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "    print('For attack1: The loss is', loss_and_metrics[0], ', the accuracy is', loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Loss function\n",
    "We found that...\n",
    "So we choose the ... as the loss function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********For the optimizer_scheme Adagrad ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 91us/step - loss: 0.3015 - binary_accuracy: 0.9137\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.1538 - binary_accuracy: 0.9564\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.1111 - binary_accuracy: 0.9680\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0920 - binary_accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0812 - binary_accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0748 - binary_accuracy: 0.9848\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0698 - binary_accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0666 - binary_accuracy: 0.9853\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0644 - binary_accuracy: 0.9860\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0619 - binary_accuracy: 0.9863\n",
      "6118/6118 [==============================] - 1s 120us/step\n",
      "For attack1: The loss is 0.06400303794214171 , the accuracy is 0.9844720492218008\n",
      "***********For the optimizer_scheme SGD ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 91us/step - loss: 0.5831 - binary_accuracy: 0.6862\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.5206 - binary_accuracy: 0.6862\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.4651 - binary_accuracy: 0.7894\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.4193 - binary_accuracy: 0.8986\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.3820 - binary_accuracy: 0.9055\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3510 - binary_accuracy: 0.9139\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.3250 - binary_accuracy: 0.9188\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.3041 - binary_accuracy: 0.9232\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 15us/step - loss: 0.2866 - binary_accuracy: 0.9280\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.2721 - binary_accuracy: 0.9298\n",
      "6118/6118 [==============================] - 1s 124us/step\n",
      "For attack1: The loss is 0.2556673607753359 , the accuracy is 0.9355998687706729\n",
      "***********For the optimizer_scheme RMSprop ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 93us/step - loss: 0.3196 - binary_accuracy: 0.8977\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.1229 - binary_accuracy: 0.9611\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0768 - binary_accuracy: 0.9816\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0653 - binary_accuracy: 0.9841\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0614 - binary_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0581 - binary_accuracy: 0.9858\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0562 - binary_accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0532 - binary_accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 16us/step - loss: 0.0515 - binary_accuracy: 0.9871\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 17us/step - loss: 0.0493 - binary_accuracy: 0.9876\n",
      "6118/6118 [==============================] - 1s 126us/step\n",
      "For attack1: The loss is 0.04279050316592181 , the accuracy is 0.9888852561326852\n",
      "***********For the optimizer_scheme Adadelta ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 99us/step - loss: 0.6976 - binary_accuracy: 0.6461\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 31us/step - loss: 0.3961 - binary_accuracy: 0.9193\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 0.2675 - binary_accuracy: 0.9336\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 0.2040 - binary_accuracy: 0.9403\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.1459 - binary_accuracy: 0.9585\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 0.1030 - binary_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 34us/step - loss: 0.0819 - binary_accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.0702 - binary_accuracy: 0.9855\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 36us/step - loss: 0.0630 - binary_accuracy: 0.9859\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 37us/step - loss: 0.0586 - binary_accuracy: 0.9866\n",
      "6118/6118 [==============================] - 1s 229us/step\n",
      "For attack1: The loss is 0.06580666823957472 , the accuracy is 0.984472049689441\n",
      "***********For the optimizer_scheme Adam ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 2s 99us/step - loss: 0.3840 - binary_accuracy: 0.8562\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.1421 - binary_accuracy: 0.9601\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0861 - binary_accuracy: 0.9821\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0711 - binary_accuracy: 0.9843\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0652 - binary_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0598 - binary_accuracy: 0.9861\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0563 - binary_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0574 - binary_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0545 - binary_accuracy: 0.9869\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 0s 20us/step - loss: 0.0530 - binary_accuracy: 0.9871\n",
      "6118/6118 [==============================] - 1s 176us/step\n",
      "For attack1: The loss is 0.04695786542072527 , the accuracy is 0.9892121603692345\n",
      "***********For the optimizer_scheme Adamax ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 4s 181us/step - loss: 0.3242 - binary_accuracy: 0.8921\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 1s 39us/step - loss: 0.1429 - binary_accuracy: 0.9564\n",
      "Epoch 3/10\n",
      "24470/24470 [==============================] - 1s 40us/step - loss: 0.0858 - binary_accuracy: 0.9808\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 1s 43us/step - loss: 0.0696 - binary_accuracy: 0.9839\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 1s 40us/step - loss: 0.0622 - binary_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 1s 39us/step - loss: 0.0580 - binary_accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 1s 40us/step - loss: 0.0559 - binary_accuracy: 0.9867\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 0.0541 - binary_accuracy: 0.9872\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 33us/step - loss: 0.0529 - binary_accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 32us/step - loss: 0.0514 - binary_accuracy: 0.9877\n",
      "6118/6118 [==============================] - 2s 246us/step\n",
      "For attack1: The loss is 0.05320551450449234 , the accuracy is 0.987087282938831\n",
      "***********For the optimizer_scheme Nadam ***********\n",
      "Epoch 1/10\n",
      "24470/24470 [==============================] - 5s 187us/step - loss: 0.2521 - binary_accuracy: 0.9231\n",
      "Epoch 2/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0848 - binary_accuracy: 0.9787\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24470/24470 [==============================] - 0s 20us/step - loss: 0.0684 - binary_accuracy: 0.9827\n",
      "Epoch 4/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0617 - binary_accuracy: 0.9852\n",
      "Epoch 5/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0543 - binary_accuracy: 0.9877\n",
      "Epoch 6/10\n",
      "24470/24470 [==============================] - 0s 19us/step - loss: 0.0575 - binary_accuracy: 0.9867\n",
      "Epoch 7/10\n",
      "24470/24470 [==============================] - 0s 18us/step - loss: 0.0484 - binary_accuracy: 0.9885\n",
      "Epoch 8/10\n",
      "24470/24470 [==============================] - 1s 29us/step - loss: 0.0588 - binary_accuracy: 0.9841\n",
      "Epoch 9/10\n",
      "24470/24470 [==============================] - 1s 43us/step - loss: 0.0486 - binary_accuracy: 0.9866\n",
      "Epoch 10/10\n",
      "24470/24470 [==============================] - 1s 44us/step - loss: 0.0426 - binary_accuracy: 0.9887\n",
      "6118/6118 [==============================] - 2s 255us/step\n",
      "For attack1: The loss is 0.04488159225107058 , the accuracy is 0.987904543500977\n"
     ]
    }
   ],
   "source": [
    "activation_func_use = activation_func[0]\n",
    "loss_func_use = loss_func[0]\n",
    "optimizer_scheme_use = optimizer_scheme[0]\n",
    "\n",
    "for i in range(len(optimizer_scheme)):\n",
    "    optimizer_scheme_use = optimizer_scheme[i]\n",
    "    print('***********For the optimizer_scheme', optimizer_scheme[i], '***********')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "    model.add(Dense(16, activation=activation_func_use))\n",
    "    model.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "    model.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "    loss_and_metrics = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "    print('For attack1: The loss is', loss_and_metrics[0], ', the accuracy is', loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the proper Optimizer\n",
    "We found that...\n",
    "So we decided to choose the ... as the Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attack2 = pd.read_csv(\"dataset/attack2with7FeatureVector.csv\")\n",
    "data_attack2 = data_attack2.dropna(axis=0, how=\"any\")#remove invalid data\n",
    "data_attack2['Label'] = data_attack2['Label']/2\n",
    "sum(np.array(data_attack2['Label']))/data_attack2['Label'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X = data_attack2.iloc[:,12:] \n",
    "n = X.shape[1]\n",
    "y = data_attack2.iloc[:,11]\n",
    "X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "y = np.reshape(y.values, (y.shape[0],  1))\n",
    "y = y/2\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "model2.add(Dense(16, activation=activation_func_use))\n",
    "model2.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "model2.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "loss_and_metrics2 = model2.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "print('The loss is', loss_and_metrics2[0], ', the accuracy is', loss_and_metrics2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attack4 = pd.read_csv(\"dataset/attack4with7FeatureVector.csv\")\n",
    "data_attack4 = data_attack4.dropna(axis=0, how=\"any\")#remove invalid data\n",
    "data_attack4['Label'] = data_attack4['Label']/4\n",
    "sum(np.array(data_attack4['Label']))/data_attack4['Label'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data_attack4.iloc[:,12:] #In our case, we use the feature of 1-6, the feature of distance rejected\n",
    "n = X.shape[1]\n",
    "y = data_attack4.iloc[:,11]\n",
    "X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "y =np.reshape(y.values, (y.shape[0],  1))\n",
    "y = y/4\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "model4.add(Dense(16, activation=activation_func_use))\n",
    "model4.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "model4.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "model4.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "loss_and_metrics4 = model4.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print('For attack4: The loss is', loss_and_metrics4[0], ', the accuracy is', loss_and_metrics4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attack8 = pd.read_csv(\"dataset/attack8with7FeatureVector.csv\")\n",
    "data_attack8 = data_attack8.dropna(axis=0, how=\"any\")#remove invalid data\n",
    "data_attack8['Label'] = data_attack8['Label']/8\n",
    "sum(np.array(data_attack8['Label']))/data_attack8['Label'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data_attack8.iloc[:,12:] #In our case, we use the feature of 1-6, the feature of distance rejected\n",
    "n = X.shape[1]\n",
    "y = data_attack8.iloc[:,11]\n",
    "X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "y =np.reshape(y.values, (y.shape[0],  1))\n",
    "\n",
    "model8 = Sequential()\n",
    "model8.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "model8.add(Dense(16, activation=activation_func_use))\n",
    "model8.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "model8.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "model8.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "loss_and_metrics8 = model8.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print('For attack8: The loss is', loss_and_metrics8[0], ', the accuracy is', loss_and_metrics8[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attack16 = pd.read_csv(\"dataset/attack16with7FeatureVector.csv\")\n",
    "data_attack16 = data_attack16.dropna(axis=0, how=\"any\")#remove invalid data\n",
    "data_attack16['Label'] = data_attack16['Label']/16\n",
    "sum(np.array(data_attack16['Label']))/data_attack16['Label'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_attack16.iloc[:,12:] #In our case, we use the feature of 1-6, the feature of distance rejected\n",
    "n = X.shape[1]\n",
    "y = data_attack16.iloc[:,11]\n",
    "X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "y =np.reshape(y.values, (y.shape[0],  1))\n",
    "\n",
    "model16 = Sequential()\n",
    "model16.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "model16.add(Dense(16, activation=activation_func_use))\n",
    "model16.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "model16.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "model16.fit(X_train, y_train, epochs=10, batch_size=100)\n",
    "\n",
    "loss_and_metrics16 = model16.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print('For attack16: The loss is', loss_and_metrics16[0], ', the accuracy is', loss_and_metrics16[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overall = data_attack1.append([data_attack2, data_attack4, data_attack8, data_attack16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_overall.iloc[:,12:] #In our case, we use the feature of 1-6, the feature of distance rejected\n",
    "n = X.shape[1]\n",
    "y = data_overall.iloc[:,11]\n",
    "X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "y =np.reshape(y.values, (y.shape[0],  1))\n",
    "\n",
    "model_all = Sequential()\n",
    "model_all.add(Dense(64, input_dim=n, activation=activation_func_use))\n",
    "model_all.add(Dense(16, activation=activation_func_use))\n",
    "model_all.add(Dense(1, activation=activation_func_use))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "model_all.compile(loss=loss_func_use, optimizer=optimizer_scheme_use, metrics=['binary_accuracy'])\n",
    "\n",
    "model_all.fit(X_train, y_train, epochs=10, batch_size=200)\n",
    "\n",
    "loss_and_metrics_all = model_all.evaluate(X_test, y_test, batch_size=64)\n",
    "\n",
    "print('For overall attack: The loss is', loss_and_metrics_all[0], ', the accuracy is', loss_and_metrics_all[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
