{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we store all the functions needed for the main file. As a consequence, the main file is easier to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data(data_name):\n",
    "    # Read the original BSM data.\n",
    "    col_index = [1,2,3,4,6,7,9,10,12,13,15,16]\n",
    "    col_names = ['re_time','re_ID','re_x','re_y','tr_time','tr_ID','tr_x','tr_y','tr_vx','tr_vy','RSSI','Label']\n",
    "    \n",
    "    data_dir = 'dataset/' + data_name + '.csv'\n",
    "    \n",
    "    data = pd.read_csv(data_dir, usecols = col_index, header = None, names = col_names)\n",
    "    data = data.dropna(axis = 0, how = 'any')\n",
    "    data = data.reset_index(drop = True)\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(X):\n",
    "    distance = np.linalg.norm([X['re_x']-X['tr_x'], X['re_y']-X['tr_y']])\n",
    "    return distance\n",
    "\n",
    "def check_range(data, threshold):\n",
    "    # We obtain the index for which the distance between sender and receiver is higher 800.\n",
    "    length = data.shape[0]\n",
    "    drop_index = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        distance_this = distance(data.iloc[i])\n",
    "        if distance_this > threshold:\n",
    "            drop_index[i]=1\n",
    "    drop_index_ = np.where(drop_index>0)\n",
    "    drop_row = np.asarray(drop_index_)[0]\n",
    "    return drop_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_session(data):\n",
    "    # get the statistics of the dataset.\n",
    "    type_of_label = np.array([])\n",
    "    sender_ID = np.unique(np.array(data.iloc[:,5]))\n",
    "    \n",
    "    count_session = 0\n",
    "    length = data.shape[0]\n",
    "    \n",
    "    data_normal = data[data['Label'] == 0]\n",
    "    A = data_normal.shape[0]\n",
    "    B = A/length\n",
    "    C = 0\n",
    "    \n",
    "    \n",
    "    data_malicious = data[data['Label'] != 1]\n",
    "    a = data_malicious.shape[0]\n",
    "    b = a/length\n",
    "    c = 0\n",
    "    \n",
    "    for i in range(len(sender_ID)):\n",
    "        data_sender = data[data['tr_ID'] == sender_ID[i]]\n",
    "        sender_receiver = np.unique(np.array(data_sender.iloc[:,1]))\n",
    "        count_session += len(sender_receiver)\n",
    "        for j in range(len(sender_receiver)):\n",
    "            data_receiver = data_sender[data_sender['re_ID'] == sender_receiver[j]]\n",
    "            m = np.unique(np.array(data_receiver.iloc[:,11]))\n",
    "            if m==0:\n",
    "                C+=1\n",
    "            if m!=0:\n",
    "                c+=1\n",
    "            t = len(np.unique(np.array(data_receiver.iloc[:,11])))\n",
    "            type_of_label = np.append(type_of_label, t) \n",
    "    D = C/count_session\n",
    "    d = c/count_session\n",
    "    print('There are ',length, 'rows in the dataset' )\n",
    "    print(A, 'rows are normal, i.e., ', B, 'percent of rows in the dataset')\n",
    "    print(a, 'rows are malicious, i.e., ', b, 'percent of rows in the dataset')\n",
    "    \n",
    "    print('There are ', count_session, 'sessions in the dataset')\n",
    "    print(C, 'session are normal, i.e., ', D, 'percent of sessions in the dataset ')\n",
    "    print(c, 'session are malicious, i.e., ', d, 'percent of sessions in the dataset ')\n",
    "    \n",
    "    if np.unique(t)==1:\n",
    "        # it means for all session there are 1 labels, whether 1 or 0\n",
    "        print('For all the session, there are only', np.unique(t)[0], 'kind of label, in other word, a session is whether attack or normal')\n",
    "    return type_of_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_plausibility(receiver_of_sender):\n",
    "    #x_95 = [-5.6983, 5.2265]\n",
    "    #x_99 = [-7.1795, 7.7077]\n",
    "    #y_95 = [-8.1203, 8.0501]\n",
    "    #y_99 = [-12.1629, 12.0927]\n",
    "    \n",
    "    x_95 = [-10, 10]\n",
    "    x_99 = [-18, 18]\n",
    "    y_95 = [-10, 10]\n",
    "    y_99 = [-18, 18]\n",
    "    \n",
    "    score = []\n",
    "    length = receiver_of_sender.shape[0]\n",
    "    # for the start of the series, we think it is two. \n",
    "    score.append(2) \n",
    "    if length <=1:\n",
    "        return score\n",
    "    for k in range(length-1):\n",
    "            time_interval = (receiver_of_sender.iloc[k+1]['re_time'] - receiver_of_sender.iloc[k]['re_time'])\n",
    "\n",
    "            x_pre_95_low = receiver_of_sender.iloc[k]['tr_x'] + time_interval * (receiver_of_sender.iloc[k]['tr_vx'] +  x_95 [0] * time_interval * 0.1)\n",
    "            x_pre_95_up  = receiver_of_sender.iloc[k]['tr_x'] + time_interval * (receiver_of_sender.iloc[k]['tr_vx'] +  x_95 [1] * time_interval * 0.1)\n",
    "            x_pre_99_low = receiver_of_sender.iloc[k]['tr_x'] + time_interval * (receiver_of_sender.iloc[k]['tr_vx'] +  x_99 [0] * time_interval * 0.1)\n",
    "            x_pre_99_up  = receiver_of_sender.iloc[k]['tr_x'] + time_interval * (receiver_of_sender.iloc[k]['tr_vx'] +  x_99 [1] * time_interval * 0.1)\n",
    "\n",
    "            y_pre_95_low = receiver_of_sender.iloc[k]['tr_y'] + time_interval * (receiver_of_sender.iloc[k]['tr_vy'] +  y_95 [0] * time_interval * 0.1)\n",
    "            y_pre_95_up  = receiver_of_sender.iloc[k]['tr_y'] + time_interval * (receiver_of_sender.iloc[k]['tr_vy'] +  y_95 [1] * time_interval * 0.1)\n",
    "            y_pre_99_low = receiver_of_sender.iloc[k]['tr_y'] + time_interval * (receiver_of_sender.iloc[k]['tr_vy'] +  y_99 [0] * time_interval * 0.1)\n",
    "            y_pre_99_up  = receiver_of_sender.iloc[k]['tr_y'] + time_interval * (receiver_of_sender.iloc[k]['tr_vy'] +  y_95 [1] * time_interval * 0.1)\n",
    "\n",
    "            t_x = 0\n",
    "            t_y = 0\n",
    "            \n",
    "            #print(receiver_of_sender.iloc[k+1]['tr_x'])\n",
    "            if receiver_of_sender.iloc[k+1]['tr_x']<=x_pre_95_low or receiver_of_sender.iloc[k+1]['tr_x'] >= x_pre_95_up:\n",
    "                t_x = 1\n",
    "\n",
    "            if receiver_of_sender.iloc[k+1]['tr_x']<=x_pre_99_low or receiver_of_sender.iloc[k+1]['tr_x'] >= x_pre_99_up:\n",
    "                t_x = 2\n",
    "\n",
    "            if receiver_of_sender.iloc[k+1]['tr_y']<=y_pre_95_low or receiver_of_sender.iloc[k+1]['tr_y'] >= y_pre_95_up:\n",
    "                t_y = 1\n",
    "\n",
    "            if receiver_of_sender.iloc[k+1]['tr_y']<=y_pre_99_low or receiver_of_sender.iloc[k+1]['tr_y'] >= y_pre_99_up:\n",
    "                t_y = 2  \n",
    "                \n",
    "            score.append(t_x+t_y)\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movement_plausibility(receiver_of_sender):\n",
    "    flag  = 0.\n",
    "    length = receiver_of_sender.shape[0]\n",
    "    \n",
    "    if length <=1:\n",
    "        flag = np.random.randint(2)\n",
    "        return flag\n",
    "    \n",
    "    x_placement = receiver_of_sender.iloc[-1]['tr_x'] - receiver_of_sender.iloc[0]['tr_x']\n",
    "    y_placement = receiver_of_sender.iloc[-1]['tr_y'] - receiver_of_sender.iloc[0]['tr_y']\n",
    "\n",
    "    average_velocity_x = np.average(receiver_of_sender['tr_vx'].values)\n",
    "    average_velocity_y = np.average(receiver_of_sender['tr_vy'].values)\n",
    "    if(x_placement==0 and y_placement==0):\n",
    "        if (average_velocity_x!=0 or average_velocity_y!=0):\n",
    "            flag = 1.\n",
    "\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantititative_information(receiver_of_sender):\n",
    "    feature3 = []\n",
    "    feature4 = []\n",
    "    feature5 = []\n",
    "    feature6 = []\n",
    "    \n",
    "    length = receiver_of_sender.shape[0]\n",
    "    \n",
    "    if length == 1:\n",
    "        feature3 = [0]\n",
    "        feature4 = [0]\n",
    "        feature5 = [0]\n",
    "        feature6 = [0]\n",
    "        return feature3, feature4, feature5, feature6\n",
    "    \n",
    "    time_interval = receiver_of_sender.iloc[-1]['re_time'] - receiver_of_sender.iloc[0]['re_time']\n",
    "    v_bar_dist_x = (receiver_of_sender.iloc[-1]['tr_x'] - receiver_of_sender.iloc[0]['tr_x'])/(time_interval)\n",
    "    v_bar_dist_y = (receiver_of_sender.iloc[-1]['tr_y'] - receiver_of_sender.iloc[0]['tr_y'])/(time_interval)\n",
    "    \n",
    "    # Calculate the v_velocity\n",
    "    v_bar_velocity_all_x = 0\n",
    "    v_bar_velocity_all_y = 0\n",
    "    for i in range(length-1):\n",
    "        delta_t = receiver_of_sender.iloc[i+1]['re_time'] - receiver_of_sender.iloc[i]['re_time']\n",
    "        v_bar_velocity_all_x = v_bar_velocity_all_x + receiver_of_sender.iloc[i]['tr_vx'] * delta_t\n",
    "        v_bar_velocity_all_y = v_bar_velocity_all_y + receiver_of_sender.iloc[i]['tr_vy'] * delta_t\n",
    "    v_bar_velo_x = v_bar_velocity_all_x/time_interval\n",
    "    v_bar_velo_y = v_bar_velocity_all_y/time_interval\n",
    "    \n",
    "    v_measure_x = np.abs(v_bar_dist_x - v_bar_velo_x)\n",
    "    v_measure_y = np.abs(v_bar_dist_y - v_bar_velo_y)\n",
    "    v_mag = np.linalg.norm([v_measure_x, v_measure_y])\n",
    "\n",
    "    v_total = np.abs(np.linalg.norm([v_bar_dist_x*time_interval, v_bar_dist_y*time_interval]) \n",
    "                     - np.linalg.norm([v_bar_velocity_all_x, v_bar_velocity_all_y]))\n",
    "    \n",
    "    feature3 = v_measure_x\n",
    "    feature4 = v_measure_y\n",
    "    feature5 = v_mag \n",
    "    feature6 = v_total\n",
    "    return feature3, feature4, feature5, feature6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_check(receiver_of_sender, threshold):\n",
    "    length = receiver_of_sender.shape[0]\n",
    "    distance_score = []\n",
    "    for i in range(length):\n",
    "        distance_score.append(0)\n",
    "        x = receiver_of_sender.iloc[i]['tr_x'] - receiver_of_sender.iloc[i]['re_x']\n",
    "        y = receiver_of_sender.iloc[i]['tr_y'] - receiver_of_sender.iloc[i]['re_y']\n",
    "        distance = np.linalg.norm([x,y])\n",
    "        if distance >= 800:\n",
    "            distance_score[i] = 1\n",
    "    return np.mean(distance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_vectors(data):\n",
    "    \n",
    "    sender_ID = np.unique(np.array(data.iloc[:,5]))\n",
    "    number_id_tr_s = len(sender_ID)\n",
    "\n",
    "    for i in range(number_id_tr_s):\n",
    "        this = data.loc[(data['tr_ID'] == sender_ID[i])]\n",
    "        this_recevier_ID = np.unique(np.array(this.iloc[:,1]))\n",
    "        number_id_re_s = len(this_recevier_ID)\n",
    "        for j in range(number_id_re_s):\n",
    "            b = this.loc[this['re_ID'] == this_recevier_ID[j]]\n",
    "            \n",
    "            feature_1 = location_plausibility(b)\n",
    "            feature_2 = movement_plausibility(b)\n",
    "            feature_3,feature_4,feature_5,feature_6 = quantititative_information(b)\n",
    "            feature_7 = distance_check(b, 800)\n",
    "            \n",
    "            b = b.head(1)\n",
    "            \n",
    "            b['feature_1'] = feature_1\n",
    "            b['feature_2'] = feature_2\n",
    "            b['feature_3'] = feature_3\n",
    "            b['feature_4'] = feature_4\n",
    "            b['feature_5'] = feature_5\n",
    "            b['feature_6'] = feature_6\n",
    "            b['feature_7'] = feature_7\n",
    "            \n",
    "            if i==0 and j==0:\n",
    "                feature_vector = b\n",
    "            else:\n",
    "                feature_vector = pd.concat([feature_vector, b])\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def put_csv(data_with_features, attack_type):\n",
    "    # we put the extracted feature vector into the csv file. \n",
    "    outname = './attack'+ str(attack_type) +'with7FeatureVector.csv'\n",
    "    outdir = './dataset'\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    fullname = './dataset/attack'+ str(attack_type) +'with7FeatureVector.csv'   \n",
    "    \n",
    "    data_with_features.to_csv(fullname, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network: Construction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vector_data(data_name):\n",
    "    # read the feature vector data from csv file.\n",
    "    \n",
    "    data_dir = 'dataset/' + data_name + '.csv'\n",
    "    \n",
    "    data = pd.read_csv(data_dir)\n",
    "    data = data.dropna(axis = 0, how = 'any')\n",
    "    data = data.reset_index(drop = True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def evaluate_model(y_predict, y_test):\n",
    "    # Our evaluation function. \n",
    "    count_ccr = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_predict[i]==y_test[i]:\n",
    "            count_ccr+=1\n",
    "        if y_predict[i]==1 and y_test[i]==1:\n",
    "            TP+=1\n",
    "        if y_predict[i]==1 and y_test[i]==0:\n",
    "            FP+=1\n",
    "        if y_predict[i]==0 and y_test[i]==1:\n",
    "            FN+=1\n",
    "    ccr = count_ccr/len(y_test)\n",
    "    if (TP+FP)==0:\n",
    "        print('All the prediction is normal')\n",
    "        preci = 0\n",
    "    else:\n",
    "        preci = TP/(TP+FP)\n",
    "    recall= TP/(TP+FN)\n",
    "    print('For this model, the CCR is', ccr, ', the Precision is', preci, 'and the Recall is', recall )\n",
    "    \n",
    "def stats(y, y_train, y_test, y_predict):\n",
    "    # displays the statistics\n",
    "    print('There are ', len(y), 'session in total')\n",
    "    \n",
    "    malicious_train = sum(y_train)/len(y_train)\n",
    "    normal_train = 1-malicious_train\n",
    "    print('The training dataset has,', len(y_train), 'sessions, there are ', malicious_train, 'malicious data, and', normal_train, 'normal data')\n",
    "    \n",
    "    malicious_test = sum(y_test)/len(y_test)\n",
    "    normal_test = 1-malicious_test\n",
    "    print('The testing dataset has',len(y_test), 'sessions, and there are ', malicious_test, 'malicious data, and', normal_test, 'normal data')\n",
    "    \n",
    "    malicious_predict = sum(y_predict)/len(y_predict)\n",
    "    normal_predict = 1-malicious_predict\n",
    "    print('The prediction includes ', malicious_predict, 'malicious data, and', normal_predict, 'normal data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_model(data, Hyper_parameter, NN_structure):\n",
    "    \n",
    "    X = data.iloc[:,12:] \n",
    "    n = X.shape[1]\n",
    "    y = data.iloc[:,11]\n",
    "    X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "    y = np.reshape(y.values, (y.shape[0],  1))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(NN_structure[0], input_dim=n, activation = Hyper_parameter[0]))\n",
    "    model.add(Dense(NN_structure[1], activation = Hyper_parameter[0]))\n",
    "    model.add(Dense(NN_structure[2], activation = Hyper_parameter[0]))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "    model.compile(loss = Hyper_parameter[1], optimizer = Hyper_parameter[2], metrics = [Hyper_parameter[3]])\n",
    "    model.fit(X_train, y_train, epochs=15, batch_size=128)\n",
    "    \n",
    "    print('***********************************************')\n",
    "    y_predict = np.round(model.predict(X_test))\n",
    "    evaluate_model(y_predict, y_test)\n",
    "    stats(y,y_train, y_test, y_predict)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(malicicous_1, malicicous_2, malicicous_4, malicicous_8, malicicous_16):\n",
    "    len1 = malicicous_1.shape[0]\n",
    "    len2 = malicicous_2.shape[0]\n",
    "    len4 = malicicous_4.shape[0]\n",
    "    len8 = malicicous_8.shape[0]\n",
    "    len16 = malicicous_16.shape[0]\n",
    "\n",
    "    length = (len1 + len2 + len4 + len8 + len16)\n",
    "    malicious_labels = np.zeros((length, 5))\n",
    "    for i in range(length):\n",
    "        if i < len1:\n",
    "            malicious_labels[i, 0] = 1\n",
    "        if i >= len1 and i< (len1+len2):\n",
    "            malicious_labels[i, 1] = 1\n",
    "        if i >= (len1+len2) and i< (len1+len2+len4):\n",
    "            malicious_labels[i, 2] = 1\n",
    "        if i >= (len1+len2+len4) and i< (len1+len2+len4+len8):\n",
    "            malicious_labels[i, 3] = 1\n",
    "        if i >= (len1+len2+len4+len8):\n",
    "            malicious_labels[i, 4] = 1\n",
    "    return malicious_labels\n",
    "\n",
    "def check_multi_classification(t,y_test):\n",
    "    a = np.argmax(t, axis=1)\n",
    "    b = np.argmax(y_test, axis=1)\n",
    "    length = len(b)\n",
    "    results_table = np.zeros((5,5))\n",
    "    for i in range(length):\n",
    "        if b[i] == 0:\n",
    "            if a[i] == 0:\n",
    "                results_table[0,0]+=1\n",
    "            if a[i] == 1:\n",
    "                results_table[0,1]+=1\n",
    "            if a[i] == 2:\n",
    "                results_table[0,2]+=1\n",
    "            if a[i] == 3:\n",
    "                results_table[0,3]+=1\n",
    "            if a[i] == 4:\n",
    "                results_table[0,4]+=1\n",
    "        if b[i] == 1:\n",
    "            if a[i] == 0:\n",
    "                results_table[1,0]+=1\n",
    "            if a[i] == 1:\n",
    "                results_table[1,1]+=1\n",
    "            if a[i] == 2:\n",
    "                results_table[1,2]+=1\n",
    "            if a[i] == 3:\n",
    "                results_table[1,3]+=1\n",
    "            if a[i] == 4:\n",
    "                results_table[1,4]+=1\n",
    "        if b[i] == 2:\n",
    "            if a[i] == 0:\n",
    "                results_table[2,0]+=1\n",
    "            if a[i] == 1:\n",
    "                results_table[2,1]+=1\n",
    "            if a[i] == 2:\n",
    "                results_table[2,2]+=1\n",
    "            if a[i] == 3:\n",
    "                results_table[2,3]+=1\n",
    "            if a[i] == 4:\n",
    "                results_table[2,4]+=1\n",
    "        if b[i] == 3:\n",
    "            if a[i] == 0:\n",
    "                results_table[3,0]+=1\n",
    "            if a[i] == 1:\n",
    "                results_table[3,1]+=1\n",
    "            if a[i] == 2:\n",
    "                results_table[3,2]+=1\n",
    "            if a[i] == 3:\n",
    "                results_table[3,3]+=1\n",
    "            if a[i] == 4:\n",
    "                results_table[3,4]+=1\n",
    "        if b[i] == 4:\n",
    "            if a[i] == 0:\n",
    "                results_table[4,0]+=1\n",
    "            if a[i] == 1:\n",
    "                results_table[4,1]+=1\n",
    "            if a[i] == 2:\n",
    "                results_table[4,2]+=1\n",
    "            if a[i] == 3:\n",
    "                results_table[4,3]+=1\n",
    "            if a[i] == 4:\n",
    "                results_table[4,4]+=1\n",
    "    MM_per = np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        MM_per[i,:] = results_table[i,:]/sum(results_table[i,:])\n",
    "    \n",
    "    return MM_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_model(data, label, Hyper_parameter, NN_structure):\n",
    "    X = data.iloc[:,12:] \n",
    "    n = X.shape[1]\n",
    "    y = label\n",
    "    X = np.reshape(X.values, (X.shape[0], X.shape[1]))\n",
    "\n",
    "    model_all = Sequential()\n",
    "    model_all.add(Dense(NN_structure[0], input_dim=n, activation=Hyper_parameter[0]))\n",
    "    model_all.add(Dense(NN_structure[1], activation=Hyper_parameter[0]))\n",
    "    model_all.add(Dense(NN_structure[2], activation=Hyper_parameter[0]))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, )\n",
    "\n",
    "    model_all.compile(loss=Hyper_parameter[1], optimizer=Hyper_parameter[2], metrics=[Hyper_parameter[3]])\n",
    "\n",
    "    model_all.fit(X_train, y_train, epochs=20, batch_size=100)\n",
    "    \n",
    "    t = model_all.predict(X_test)\n",
    "    evaluation_matrix = check_multi_classification(t,y_test)\n",
    "    print(evaluation_matrix)\n",
    "    return model_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, mode):\n",
    "    # Randomly pick a transmission session from the dataset. \n",
    "    data_category = data.loc[(data['Label']==mode)]\n",
    "    data_sender_ID = np.unique(np.array(data_category.iloc[:,5]))\n",
    "    n = np.random.randint(len(data_sender_ID))\n",
    "    data_sender = data_category.loc[data_category['tr_ID'] == data_sender_ID[n]]\n",
    "    data_recevier_ID = np.unique(np.array(data_sender.iloc[:,1]))\n",
    "    m = np.random.randint(len(data_recevier_ID))\n",
    "    data_select = data_sender.loc[data_sender['re_ID']==data_recevier_ID[m]]\n",
    "    if data_select.shape[0]==1:\n",
    "        return get_data(data, mode)\n",
    "    return data_select\n",
    "\n",
    "def test_real_data(model, data, mode):\n",
    "    # Test whether the data is malicious or not.\n",
    "    data_vector =np.zeros((1, 7))\n",
    "    data_vector[0][0] = location_plausibility(data)\n",
    "    data_vector[0][1] = movement_plausibility(data)\n",
    "    data_vector[0][2], data_vector[0][3], data_vector[0][4], data_vector[0][5] =quantititative_information(data)\n",
    "    data_vector[0][6] = distance_check(data,800)\n",
    "    \n",
    "    y_predict = np.round(model.predict(data_vector))\n",
    "    \n",
    "    if y_predict==1:\n",
    "        print('The detection system said: The BSM is malicious!')\n",
    "        if mode==1:\n",
    "            print('The detection is correct!')\n",
    "        else:\n",
    "            print('But in fact, the BSM is normal, the detection is incorrect')\n",
    "    if y_predict==0:\n",
    "        print('The detection system said: The BSM is normal!')\n",
    "        if mode==0:\n",
    "            print('The detection is correct!')\n",
    "        else:\n",
    "            print('But in fact, the BSM is malicious, the detection is incorrect')\n",
    "\n",
    "def classification(model, data, n):\n",
    "    \n",
    "    data_vector =np.zeros((1, 7))\n",
    "    data_vector[0][0] = location_plausibility(data)\n",
    "    data_vector[0][1] = movement_plausibility(data)\n",
    "    data_vector[0][2], data_vector[0][3], data_vector[0][4], data_vector[0][5] =quantititative_information(data)\n",
    "    data_vector[0][6] = distance_check(data,800)\n",
    "    \n",
    "    y_predict = model.predict(data_vector)\n",
    "    \n",
    "    t = np.argmax(y_predict)\n",
    "    \n",
    "    if t == n :\n",
    "        print('The classification is correct!')\n",
    "    if t != n :\n",
    "        print('The classification is incorrect:')\n",
    "        print('The attack is ', atk_type[n], ', however, the model classifies it as ', atk_type[t])\n",
    "        \n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def validation(input_type, mode):\n",
    "    data = get_data(raw_data[input_type], mode)\n",
    "    print('The session we randomly choose from the dataset', atk_type[input_type], ' is shown as follows')\n",
    "    display(data)\n",
    "    print('*************We firstly check whether it is malicious by its corresponding model*************')\n",
    "    test_real_data(model_trained[input_type], data, mode)\n",
    "    print('*************We then check whether it is malicious by its general model*************')\n",
    "    test_real_data(model_all, data, mode)\n",
    "    \n",
    "    if mode==1:\n",
    "        print('*************If it is malicious, we classify it*************')\n",
    "        classification(model_classification, data, input_type)\n",
    "    if mode!=1:\n",
    "        print('The session is normal!!!')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
